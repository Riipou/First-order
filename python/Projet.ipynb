{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Riipou/First-order/blob/main/python/Projet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "bl83xkta8l4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "import numpy as np\n",
        "import csv"
      ],
      "metadata": {
        "id": "N-hIFm_oAlSB"
      },
      "execution_count": 323,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chargement et pré-traitement des données"
      ],
      "metadata": {
        "id": "SYh8dg7z8O3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encoding(y):\n",
        "    new_y = []\n",
        "    for label in y:\n",
        "        label_vector = np.zeros(20)\n",
        "        label_vector[label - 1] = 1\n",
        "        new_y.append(label_vector)\n",
        "    y = np.array(new_y)\n",
        "    return y\n",
        "\n",
        "\n",
        "def shuffle(X, y):\n",
        "    index = np.arange(np.shape(X)[1])\n",
        "    np.random.shuffle(index)\n",
        "    X = X[:, index]\n",
        "    y = y.T[:, index]\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def split_data(X, y, split_value=0.8):\n",
        "    m = X.shape[1]\n",
        "    m = int(m * split_value)\n",
        "    X_train = X[:, :m]\n",
        "    y_train = y[:m, :]\n",
        "    X_test = X[:, m:]\n",
        "    y_test = y[m:, :]\n",
        "    return X_train, y_train, X_test, y_test\n"
      ],
      "metadata": {
        "id": "MDPtzI948q-e"
      },
      "execution_count": 324,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Charger le fichier .mat\n",
        "nom_fichier_mat = 'data_doc.mat'\n",
        "donnees = loadmat(nom_fichier_mat)\n",
        "\n",
        "# Xts combien de fois le mot dans le texte\n",
        "if 'Xts' in donnees:\n",
        "    Xts = donnees['Xts']\n",
        "else:\n",
        "    print(\"La variable 'Xts' n'a pas été trouvée dans le fichier.\")\n",
        "\n",
        "# id texte avec classe\n",
        "if 'yts' in donnees:\n",
        "    yts = donnees['yts']\n",
        "else:\n",
        "    print(\"La variable 'yts' n'a pas été trouvée dans le fichier.\")\n",
        "\n",
        "# Xvr combien de fois le mot dans le texte\n",
        "if 'Xvr' in donnees:\n",
        "    Xvr = donnees['Xvr']\n",
        "else:\n",
        "    print(\"La variable 'Xvr' n'a pas été trouvée dans le fichier.\")\n",
        "\n",
        "yts = one_hot_encoding(yts)\n",
        "Xts, yts = shuffle(Xts, yts)\n",
        "# X_train, y_train, X_test, y_test = split_data(Xts, yts)"
      ],
      "metadata": {
        "id": "O0WvebYQ8Obr"
      },
      "execution_count": 325,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Descente du gradient"
      ],
      "metadata": {
        "id": "9P5g_HL68dYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(y, y_pred):\n",
        "    n = y.shape[1]\n",
        "    loss = (np.linalg.norm(y - y_pred, 'fro') ** 2) / n\n",
        "    return loss\n",
        "\n",
        "def sigmoid(X, a):\n",
        "    return 1 / (1 + np.exp(-a * X))\n",
        "\n",
        "def sigmoid_derivate(X, a):\n",
        "    return a * sigmoid(X, a) * (1 - sigmoid(X, a))\n",
        "\n",
        "def relu(x, a):\n",
        "    return np.maximum(0, a * x)\n",
        "\n",
        "def initialization_random(m, p):\n",
        "    W = np.random.rand(m, p) - 0.5\n",
        "    b = np.random.rand(p) - 0.5\n",
        "    return W, b\n",
        "\n",
        "def initialization_xavier(m, p):\n",
        "    W = np.random.randn(m, p) * np.sqrt(2 / (m + p))\n",
        "    b = np.zeros((p,))\n",
        "    return W, b\n",
        "\n",
        "def initialization_lecun(m, p):\n",
        "    W = np.random.randn(m, p) * np.sqrt(1 / m)\n",
        "    b = np.zeros((p,))\n",
        "    return W, b\n",
        "\n",
        "def grad_W(W, B, a, X, y, n):\n",
        "    return X @ ((1 / n) * np.multiply(sigmoid(W.T @ X + B, a) - y, sigmoid_derivate(W.T @ X + B, a))).T\n",
        "\n",
        "def grad_B(W, B, a, X, y, n):\n",
        "    v1 = np.ones((n, 1))\n",
        "    return ((1 / n) * np.multiply(sigmoid(W.T @ X + B, a) - y, sigmoid_derivate(W.T @ X + B, a))) @ v1\n",
        "\n",
        "def evol_beta_paul(k):\n",
        "    return  (k-1)/(k+2)\n",
        "\n",
        "def evol_beta_nesterov(alpha_b):\n",
        "    alpha_b2 = (np.sqrt((alpha_b**4) + 4*alpha_b**2) - alpha_b**2) / 2\n",
        "    beta = (alpha_b * (1 - alpha_b)) / (alpha_b**2 + alpha_b2)\n",
        "    return beta, alpha_b2"
      ],
      "metadata": {
        "id": "hHUABdqjZwWW"
      },
      "execution_count": 326,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descente de gradient"
      ],
      "metadata": {
        "id": "VanXa1rM8ZM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_W(alpha, W, B, a, X, y):\n",
        "    loss = loss_function(y, sigmoid(W.T @ X + B, a))\n",
        "    alpha *= 1.5\n",
        "    W2 = W - alpha * grad_W(W, B, a, X, y, n)\n",
        "    while loss_function(y, sigmoid(W2.T @ X + B, a)) > loss and alpha != (alpha/2):\n",
        "        alpha /= 2\n",
        "        W2 = W - alpha * grad_W(W, B, a, X, y, n)\n",
        "    return W2, alpha\n",
        "\n",
        "\n",
        "def update_B(alpha, W, B, a, X, y):\n",
        "    loss = loss_function(y, sigmoid(W.T @ X + B, a))\n",
        "    alpha *= 1.5\n",
        "    b = B[:, 1]\n",
        "    b = b.reshape(-1, 1)\n",
        "    b2 = b - alpha * grad_B(W, B, a, X, y, n)\n",
        "    B2 = np.tile(b2.reshape(-1), (n, 1)).T\n",
        "    while loss_function(y, sigmoid(W.T @ X + B2, a)) > loss and alpha != (alpha/2):\n",
        "        alpha /= 2\n",
        "        b2 = b - alpha * grad_B(W, B, a, X, y, n)\n",
        "        B2 = np.tile(b2.reshape(-1), (n, 1)).T\n",
        "    return B2, alpha\n",
        "\n",
        "def update_W_Polyak (alpha, W, B, a, X, y, W_prev, alpha_b, beta):\n",
        "    loss = loss_function(y, sigmoid(W.T @ X + B, a))\n",
        "    alpha *= 1.5\n",
        "\n",
        "    # Mise à jour des poids en utilisant la méthode de Polyak's\n",
        "    W2 = W - alpha * grad_W(W, B, a, X, y, n) + beta * (W - W_prev)\n",
        "\n",
        "    if loss_function(y, sigmoid(W2.T @ X + B, a)) > loss :\n",
        "        alpha /= 2\n",
        "\n",
        "        W2 = W - alpha * grad_W(W, B, a, X, y, n)\n",
        "        print(\"testW\")\n",
        "\n",
        "    return W2, alpha, W, alpha_b\n",
        "\n",
        "\n",
        "def update_B_Polyak (alpha, W, B, a, X, y, B_prev, alpha_b, beta):\n",
        "    loss = loss_function(y, sigmoid(W.T @ X + B, a))\n",
        "    alpha *= 1.5\n",
        "\n",
        "    b = B[:, 1]\n",
        "    b = b.reshape(-1, 1)\n",
        "    b_prev = B_prev[:, 1]\n",
        "    b_prev = b_prev.reshape(-1,1)\n",
        "\n",
        "    # Mise à jour des poids en utilisant la méthode de Polyak's\n",
        "    b2 = b - alpha * grad_B(W, B, a, X, y, n) + beta * (b - b_prev)\n",
        "    B2 = np.tile(b2.reshape(-1), (n, 1)).T\n",
        "\n",
        "    if loss_function(y, sigmoid(W.T @ X + B2, a)) > loss:\n",
        "        alpha /= 2\n",
        "\n",
        "        b2 = b - alpha * grad_B(W, B, a, X, y, n)\n",
        "        B2 = np.tile(b2.reshape(-1), (n, 1)).T\n",
        "\n",
        "    return B2, alpha, B, alpha_b\n",
        "\n",
        "def update_W_Nesterov(alpha, W, B, a, X, y, W_prev, alpha_b, beta):\n",
        "    loss = loss_function(y, sigmoid(W.T @ X + B, a))\n",
        "    alpha *= 1.5\n",
        "\n",
        "    # Mise à jour des poids en utilisant la méthode de Nesterov\n",
        "    shifted_point = W - beta * (W - W_prev)\n",
        "    W2 = W - alpha * grad_W(shifted_point, B, a, X, y, n) + beta * (W - W_prev)\n",
        "\n",
        "    if loss_function(y, sigmoid(W2.T @ X + B, a)) > loss :\n",
        "      alpha /= 2\n",
        "      W2 = W - alpha * grad_W(W, B, a, X, y, n)\n",
        "\n",
        "    return W2, alpha, W, alpha_b\n",
        "\n",
        "\n",
        "def update_B_Nesterov(alpha, W, B, a, X, y, B_prev, alpha_b, beta):\n",
        "    loss = loss_function(y, sigmoid(W.T @ X + B, a))\n",
        "    alpha *= 1.5\n",
        "\n",
        "    b = B[:, 1]\n",
        "    b = b.reshape(-1, 1)\n",
        "    b_prev = B_prev[:, 1]\n",
        "    b_prev = b_prev.reshape(-1,1)\n",
        "\n",
        "    # Mise à jour des poids en utilisant la méthode de Nesterov\n",
        "    shifted_point = B - beta * (B - B_prev)\n",
        "    b2 = b - alpha * grad_B(W, shifted_point, a, X, y, n) + beta * (b - b_prev)\n",
        "    B2 = np.tile(b2.reshape(-1), (n, 1)).T\n",
        "\n",
        "    if loss_function(y, sigmoid(W.T @ X + B2, a)) > loss:\n",
        "      alpha /= 2\n",
        "      b2 = b - alpha * grad_B(W, B, a, X, y, n)\n",
        "      B2 = np.tile(b2.reshape(-1), (n, 1)).T\n",
        "\n",
        "    return B2, alpha, B, alpha_b\n",
        "\n",
        "\n",
        "\n",
        "def linear_model(m, n, p, max_iterations, a, stop_condition, X, y, init, accel = \"none\", evol_b = \"paul\"):\n",
        "\n",
        "    if init == \"random\":\n",
        "        # Initialisation random pour les poids (76,987)\n",
        "        W, b = initialization_random(m, p)\n",
        "    elif init == \"xavier\":\n",
        "        # Initialisation de Xavier/Glorot pour les poids (73,513)\n",
        "        W, b = initialization_xavier(m, p)\n",
        "    elif init == \"lecun\":\n",
        "        # Initialisation de Lecun pour les poids (77,388)\n",
        "        W, b = initialization_lecun(m, p)\n",
        "\n",
        "    B = np.tile(b, (n, 1)).T\n",
        "    alpha_W = 0.1 * np.linalg.norm(W, 'fro') / np.linalg.norm(grad_W(W, B, a, X, y, n), 'fro')\n",
        "    alpha_B = 0.1 * np.linalg.norm(B, 'fro') / np.linalg.norm(grad_B(W, B, a, X, y, n), 'fro')\n",
        "\n",
        "    if accel == \"none\" :\n",
        "      for _ in range(max_iterations):\n",
        "          loss_prev = loss_function(y, sigmoid(W.T @ X + B, 1))\n",
        "          W, alpha_W = update_W(alpha_W, W, B, a, X, y)\n",
        "          B, alpha_B = update_B(alpha_B, W, B, a, X, y)\n",
        "          loss = loss_function(y, sigmoid(W.T @ X + B, 1))\n",
        "          print(loss)\n",
        "          if abs(loss - loss_prev) < stop_condition:\n",
        "              print(\"break\")\n",
        "              break\n",
        "      return W, b\n",
        "\n",
        "    elif accel == \"polyak\" :\n",
        "      W_prev = W\n",
        "      B_prev = B\n",
        "      alpha_b = 0.5\n",
        "      for k in range(1,max_iterations+1):\n",
        "\n",
        "          if evol_b == \"const\" :\n",
        "              beta = 0.5\n",
        "\n",
        "          if evol_b == \"paul\" :\n",
        "              beta = evol_beta_paul(k)\n",
        "\n",
        "          if evol_b == \"nesterov\" :\n",
        "              beta, alpha_b = evol_beta_nesterov(alpha_b)\n",
        "\n",
        "          loss_prev = loss_function(y, sigmoid(W.T @ X + B, 1))\n",
        "          W, alpha_W, W_prev, alpha_b = update_W_Polyak(alpha_W, W, B, a, X, y, W_prev, alpha_b, beta)\n",
        "          B, alpha_B, B_prev, alpha_b = update_B_Polyak(alpha_B, W, B, a, X, y, B_prev, alpha_b, beta)\n",
        "          loss = loss_function(y, sigmoid(W.T @ X + B, 1))\n",
        "          print(loss)\n",
        "          if abs(loss - loss_prev) < stop_condition:\n",
        "              print(\"break\")\n",
        "              break\n",
        "      return W, b\n",
        "\n",
        "\n",
        "    elif accel == \"nesterov\" :\n",
        "      W_prev = W\n",
        "      B_prev = B\n",
        "      alpha_b = 0.5\n",
        "      for k in range(1,max_iterations+1):\n",
        "\n",
        "          if evol_b == \"const\" :\n",
        "              beta = 0.5\n",
        "\n",
        "          if evol_b == \"paul\" :\n",
        "              beta = evol_beta_paul(k)\n",
        "\n",
        "          if evol_b == \"nesterov\" :\n",
        "              beta, alpha_b = evol_beta_nesterov(alpha_b)\n",
        "\n",
        "          loss_prev = loss_function(y, sigmoid(W.T @ X + B, 1))\n",
        "          W, alpha_W, W_prev, alpha_b = update_W_Nesterov(alpha_W, W, B, a, X, y, W_prev, alpha_b, beta)\n",
        "          B, alpha_B, B_prev, alpha_b = update_B_Nesterov(alpha_B, W, B, a, X, y, B_prev, alpha_b, beta)\n",
        "          loss = loss_function(y, sigmoid(W.T @ X + B, 1))\n",
        "          print(loss)\n",
        "          if abs(loss - loss_prev) < stop_condition:\n",
        "              print(\"break\")\n",
        "              break\n",
        "      return W, b\n",
        "\n"
      ],
      "metadata": {
        "id": "SLvTUVE5ecTV"
      },
      "execution_count": 327,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m, n = Xts.shape\n",
        "p, _ = yts.shape\n",
        "\n",
        "# Définition des variables\n",
        "num_iterations = 10000\n",
        "a = 0.05\n",
        "stop_condition = 1e-5\n",
        "# Choisir initialisation : random, xavier, lecun\n",
        "initialisation = \"lecun\"\n",
        "# Choisir acceleration : none, polyak, nesterov\n",
        "acceleration = \"nesterov\"\n",
        "# Choisir evolution beta : const, paul , nesterov\n",
        "evol_b = \"paul\"\n",
        "\n",
        "W, b = linear_model(m, n, p, num_iterations, a, stop_condition, Xts, yts, initialisation, acceleration, evol_b)\n",
        "\n"
      ],
      "metadata": {
        "id": "Ur52FKOD8X4h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "outputId": "c2c81187-a2aa-4361-d05d-3dea595048a9"
      },
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.8173265410244266\n",
            "2.702962703753734\n",
            "1.9050610735588387\n",
            "1.4596191254725956\n",
            "1.2373969280037347\n",
            "1.123187822840384\n",
            "1.0624592662300913\n",
            "1.0306951303223602\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-326-2c9294a05fed>:7: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-a * X))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.013719125095668\n",
            "1.0037942032582015\n",
            "0.9968230407099992\n",
            "0.9902469055717864\n",
            "0.9819843171583211\n",
            "0.9703333926586235\n",
            "0.9512146652978524\n",
            "0.9233864186414592\n",
            "0.8837412428706395\n",
            "0.8324326796423445\n",
            "0.7684504353883923\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-334-58925306e353>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mevol_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"paul\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_condition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitialisation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macceleration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevol_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-327-f12b35b526a6>\u001b[0m in \u001b[0;36mlinear_model\u001b[0;34m(m, n, p, max_iterations, a, stop_condition, X, y, init, accel, evol_b)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m           \u001b[0mloss_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m           \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_W_Nesterov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m           \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_B_Nesterov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m           \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-327-f12b35b526a6>\u001b[0m in \u001b[0;36mupdate_W_Nesterov\u001b[0;34m(alpha, W, B, a, X, y, W_prev, alpha_b, beta)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mupdate_W_Nesterov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0malpha\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/sparse/_base.py\u001b[0m in \u001b[0;36m__rmatmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    628\u001b[0m             raise ValueError(\"Scalar operands are not allowed, \"\n\u001b[1;32m    629\u001b[0m                              \"use '*' instead\")\n\u001b[0;32m--> 630\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rmul_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m     \u001b[0;31m####################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/sparse/_base.py\u001b[0m in \u001b[0;36m_rmul_dispatch\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m                 \u001b[0mtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/sparse/_base.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    524\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_multivector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misscalarlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/sparse/_compressed.py\u001b[0m in \u001b[0;36m_mul_multivector\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;31m# csr_matvecs or csc_matvecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sparsetools\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_matvecs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m         fn(M, N, n_vecs, self.indptr, self.indices, self.data,\n\u001b[0m\u001b[1;32m    502\u001b[0m            other.ravel(), result.ravel())\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation des données"
      ],
      "metadata": {
        "id": "qJI9qCsn7-qc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uJCkdiVX79_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cD63PHxohXrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Création validation"
      ],
      "metadata": {
        "id": "Ffv4AvSIhYEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reverse_one_hot_encoding(y):\n",
        "    y = np.argmax(y, axis=0)+1\n",
        "    return y\n",
        "\n",
        "def test(X, W, b):\n",
        "    _, n = X.shape\n",
        "    B = np.tile(b, (n, 1)).T\n",
        "    y = sigmoid(W.T @ X + B, 1)\n",
        "    y = reverse_one_hot_encoding(y)\n",
        "    ids = np.arange(1, len(y)+1)\n",
        "    data = np.column_stack((ids, 1+100 * y))\n",
        "    nom_fichier = \"test2.csv\"\n",
        "\n",
        "    header = [\"id\",\"class\"]\n",
        "    with open(nom_fichier, 'w', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow(header)\n",
        "        writer.writerows(data)\n",
        "    return 0"
      ],
      "metadata": {
        "id": "dJVFpZAeEaJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(Xvr, W, b)"
      ],
      "metadata": {
        "id": "RV6Rmf9-D7xe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}